{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5883bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c788d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"../data/fake_or_real_news.csv\")\n",
    "\n",
    "# Aperçu du dataset\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Distribution des longueurs de textes\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['text_length'], bins=50)\n",
    "plt.title(\"Distribution de la longueur des textes\")\n",
    "plt.show()\n",
    "\n",
    "# Exemple de mots fréquents pour FAKE et REAL\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from src.preprocessing import clean_text\n",
    "\n",
    "def plot_top_words(df, label, n=20):\n",
    "    texts = df[df['label']==label]['text'].apply(clean_text)\n",
    "    cv = CountVectorizer(max_features=1000)\n",
    "    X = cv.fit_transform(texts)\n",
    "    sum_words = X.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    words, freqs = zip(*words_freq)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(x=freqs, y=words)\n",
    "    plt.title(f\"Top {n} mots pour {label}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_top_words(df, \"FAKE\")\n",
    "plot_top_words(df, \"REAL\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
